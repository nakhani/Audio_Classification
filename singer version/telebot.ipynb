{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from spleeter.separator import Separator\n",
    "import os\n",
    "\n",
    "\n",
    "MODEL_PATH = \"final_model_singer.keras\"\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "\n",
    "def singer_command(update: Update, context: CallbackContext) -> None:\n",
    "    update.message.reply_text(\"Send a song ðŸŽ¶, and I will extract vocals to recognize the singer!\")\n",
    "\n",
    "\n",
    "def handle_audio(update: Update, context: CallbackContext) -> None:\n",
    "    voice = update.message.voice or update.message.audio\n",
    "    if not voice:\n",
    "        update.message.reply_text(\"Please send a valid audio file.\")\n",
    "        return\n",
    "\n",
    "   \n",
    "    audio_file = voice.get_file()\n",
    "    audio_path = \"song.ogg\"\n",
    "    audio_file.download(audio_path)\n",
    "\n",
    "    \n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    audio = audio.set_channels(1).set_frame_rate(48000)\n",
    "    processed_audio_path = \"processed_song.wav\"\n",
    "    audio.export(processed_audio_path, format=\"wav\")\n",
    "\n",
    "    \n",
    "    vocals_dir = \"spleeter_output\"\n",
    "    os.makedirs(vocals_dir, exist_ok=True)\n",
    "    \n",
    "    separator = Separator(\"spleeter:2stems\")\n",
    "    separator.separate_to_file(processed_audio_path, vocals_dir)\n",
    "\n",
    "    \n",
    "    file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    vocal_file_path = os.path.join(vocals_dir, file_name, \"vocals.wav\")\n",
    "\n",
    "    \n",
    "    audio = AudioSegment.from_file(vocal_file_path)\n",
    "    audio = audio.set_channels(1).set_frame_rate(48000).set_sample_width(2)\n",
    "    final_audio_path = \"processed_vocals.wav\"\n",
    "    audio.export(final_audio_path, format=\"wav\")\n",
    "\n",
    "   \n",
    "    audio_binary = tf.io.read_file(final_audio_path)\n",
    "    audio_tensor, _ = tf.audio.decode_wav(audio_binary, desired_channels=1, desired_samples=48000)\n",
    "\n",
    "    \n",
    "    audio_tensor = tf.expand_dims(audio_tensor, axis=0)\n",
    "\n",
    "   \n",
    "    try:\n",
    "        prediction = model.predict(audio_tensor)\n",
    "        predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "        update.message.reply_text(f\"ðŸŽ¤ Recognized singer: {predicted_class}\")\n",
    "    except Exception as e:\n",
    "        update.message.reply_text(f\"Error during prediction: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    updater = Updater(\"TOKEN\", use_context=True)\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "   \n",
    "    dispatcher.add_handler(CommandHandler(\"singer\", singer_command))\n",
    "\n",
    "    \n",
    "    dispatcher.add_handler(MessageHandler(Filters.voice | Filters.audio, handle_audio))\n",
    "\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
